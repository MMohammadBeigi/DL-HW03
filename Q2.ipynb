{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nLFT38BK2Uyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b175448d-9c27-477f-f9a3-04cb3ed7ba3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import copy\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pickle\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdLy2RIBGcp3",
        "outputId": "8871d45b-e6c6-4c6a-a724-b43555562e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'coco'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 10.48 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "/content/coco/PythonAPI\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "Compiling pycocotools/_mask.pyx because it changed.\n",
            "[1/1] Cythonizing pycocotools/_mask.pyx\n",
            "/usr/local/lib/python3.10/dist-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /content/coco/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/pycocotools\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c ../common/maskApi.c -o build/temp.linux-x86_64-cpython-310/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   46 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "      |                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  166 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "  166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  167 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "  167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  212 |       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "      |       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "  212 |       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "      |                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  220 |   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "      |   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "  220 |   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "      |                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  228 |     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "      |     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "  228 |     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c pycocotools/_mask.c -o build/temp.linux-x86_64-cpython-310/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/pycocotools\n",
            "x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/../common/maskApi.o build/temp.linux-x86_64-cpython-310/pycocotools/_mask.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating pycocotools.egg-info\n",
            "writing pycocotools.egg-info/PKG-INFO\n",
            "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
            "writing requirements to pycocotools.egg-info/requires.txt\n",
            "writing top-level names to pycocotools.egg-info/top_level.txt\n",
            "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "reading manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/pycocotools\n",
            "copying pycocotools/coco.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
            "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
            "copying pycocotools/mask.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
            "copying pycocotools/__init__.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
            "running build_ext\n",
            "building 'pycocotools._mask' extension\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/pycocotools\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c ../common/maskApi.c -o build/temp.linux-x86_64-cpython-310/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   46 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "      |                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  166 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "  166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  167 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "  167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  212 |       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "      |       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "  212 |       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "      |                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  220 |   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "      |   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "  220 |   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "      |                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmisleading-indentation\u0007-Wmisleading-indentation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  228 |     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "      |     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "  228 |     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c pycocotools/_mask.c -o build/temp.linux-x86_64-cpython-310/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/../common/maskApi.o build/temp.linux-x86_64-cpython-310/pycocotools/_mask.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-cpython-310/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-cpython-310/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-cpython-310/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-cpython-310/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-cpython-310/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-310.pyc\n",
            "creating stub loader for pycocotools/_mask.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "pycocotools.__pycache__._mask.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/pycocotools-2.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pycocotools-2.0-py3.10-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.10/dist-packages/pycocotools-2.0-py3.10-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.10/dist-packages/pycocotools-2.0-py3.10-linux-x86_64.egg\n",
            "Extracting pycocotools-2.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "pycocotools 2.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/pycocotools-2.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for pycocotools==2.0\n",
            "Searching for matplotlib==3.7.1\n",
            "Best match: matplotlib 3.7.1\n",
            "Adding matplotlib 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Cython==3.0.6\n",
            "Best match: Cython 3.0.6\n",
            "Adding Cython 3.0.6 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for setuptools==67.7.2\n",
            "Best match: setuptools 67.7.2\n",
            "Adding setuptools 67.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyparsing==3.1.1\n",
            "Best match: pyparsing 3.1.1\n",
            "Adding pyparsing 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Pillow==9.4.0\n",
            "Best match: Pillow 9.4.0\n",
            "Adding Pillow 9.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for packaging==23.2\n",
            "Best match: packaging 23.2\n",
            "Adding packaging 23.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numpy==1.23.5\n",
            "Best match: numpy 1.23.5\n",
            "Adding numpy 1.23.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.10 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for kiwisolver==1.4.5\n",
            "Best match: kiwisolver 1.4.5\n",
            "Adding kiwisolver 1.4.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fonttools==4.46.0\n",
            "Best match: fonttools 4.46.0\n",
            "Adding fonttools 4.46.0 to easy-install.pth file\n",
            "Installing fonttools script to /usr/local/bin\n",
            "Installing pyftmerge script to /usr/local/bin\n",
            "Installing pyftsubset script to /usr/local/bin\n",
            "Installing ttx script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cycler==0.12.1\n",
            "Best match: cycler 0.12.1\n",
            "Adding cycler 0.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for contourpy==1.2.0\n",
            "Best match: contourpy 1.2.0\n",
            "Adding contourpy 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for six==1.16.0\n",
            "Best match: six 1.16.0\n",
            "Adding six 1.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for pycocotools==2.0\n",
            "/content\n",
            "--2023-12-24 21:14:24--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.132.97, 52.217.230.233, 52.217.136.89, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.132.97|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "train2017.zip       100%[===================>]  18.01G  33.1MB/s    in 9m 15s  \n",
            "\n",
            "2023-12-24 21:23:39 (33.3 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
            "\n",
            "--2023-12-24 21:23:39--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.226.249, 3.5.28.161, 16.182.100.177, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.226.249|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘val2017.zip’\n",
            "\n",
            "val2017.zip         100%[===================>] 777.80M  33.2MB/s    in 24s     \n",
            "\n",
            "2023-12-24 21:24:03 (32.2 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n",
            "\n",
            "--2023-12-24 21:24:03--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.1.106, 52.217.123.57, 3.5.27.163, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.1.106|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  33.5MB/s    in 8.1s    \n",
            "\n",
            "2023-12-24 21:24:12 (29.8 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  train2017.zip\n",
            "replace train2017/000000147328.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/pdollar/coco/\n",
        "%cd coco/PythonAPI\n",
        "! make\n",
        "! python setup.py install\n",
        "%cd ../..\n",
        "! rm -r coco\n",
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip \\*.zip\n",
        "!rm *.zip\n",
        "path2data=\"./train2017\"\n",
        "path2json=\"./annotations/instances_train2017.json\"\n",
        "\n",
        "path2data_val=\"./val2017\"\n",
        "_val=\"./annotations/instances_val2017.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WhP9QYYNnCT",
        "outputId": "a58d523c-9200-4c4a-9ed5-e682c4954c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7bf0088d2050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n",
            "Exception ignored in: <function _xla_gc_callback at 0x7bf0088d2050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done (t=22.20s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=21.75s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.62s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "# Define the COCO training dataset with data transformations\n",
        "coco_train = torch.utils.data.Subset(datasets.CocoDetection(root=path2data, annFile=path2json, transform=transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the images\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image data based on ImageNet statistics\n",
        "])), [i for i in range(10240)])\n",
        "\n",
        "# Define another subset of the COCO training dataset with a different size and the same data transformations\n",
        "coco_train_2 = torch.utils.data.Subset(datasets.CocoDetection(root=path2data, annFile=path2json, transform=transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the images\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image data based on ImageNet statistics\n",
        "])), [i for i in range(4096)])\n",
        "# Define a reduced subset of the COCO validation dataset with specific transformations and size\n",
        "coco_val = torch.utils.data.Subset(datasets.CocoDetection(root=path2data_val, annFile=_val, transform=transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the images\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image data based on ImageNet statistics\n",
        "])), [i for i in range(2000)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oRDjNl59W-Y8"
      },
      "outputs": [],
      "source": [
        "# Custom PyTorch dataset class for COCO dataset\n",
        "class CocoDataset(Dataset):\n",
        "    def __init__(self, num_objects, dataset):\n",
        "        \"\"\"\n",
        "        Constructor for the CocoDataset class.\n",
        "\n",
        "        Parameters:\n",
        "        - num_objects (int): Number of object categories for one-hot encoding.\n",
        "        - dataset: Original COCO dataset.\n",
        "        \"\"\"\n",
        "        self.coco_dataset = dataset\n",
        "        self.num_objects = num_objects\n",
        "\n",
        "    def convert_to_one_hot(self, numbers, size):\n",
        "        \"\"\"\n",
        "        Convert a list of numbers to one-hot encoded tensor.\n",
        "\n",
        "        Parameters:\n",
        "        - numbers (list): List of numbers to be one-hot encoded.\n",
        "        - size (int): Size of the one-hot encoded tensor.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: One-hot encoded tensor.\n",
        "        \"\"\"\n",
        "        return torch.from_numpy(np.eye(size)[numbers])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Get a single item from the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        - index (int): Index of the item.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Placeholder 'data' (actual data loading implementation is missing).\n",
        "        - torch.Tensor: One-hot encoded labels for object categories.\n",
        "        \"\"\"\n",
        "        # Note: The 'data' placeholder should be replaced with actual data loading code\n",
        "        data, target = self.coco_dataset[index];\n",
        "        return data, self.convert_to_one_hot([target[i]['category_id']-1 for i in range(len(target))], self.num_objects)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the length of the dataset.\n",
        "\n",
        "        Returns:\n",
        "        - int: Length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.coco_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7u83vtRTo0uV"
      },
      "outputs": [],
      "source": [
        "# Create data loaders for training and testing datasets\n",
        "train_data_loader1 = DataLoader(CocoDataset(90, coco_train), batch_size=64, shuffle=True)  # Training data loader 1\n",
        "train_data_loader2 = DataLoader(CocoDataset(90, coco_train_2), batch_size=64, shuffle=True)  # Training data loader 2\n",
        "test_data_loader = DataLoader(CocoDataset(90, coco_val), batch_size=64, shuffle=True)  # Testing data loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DPZpTCWeyYCX"
      },
      "outputs": [],
      "source": [
        "# Custom Deformable Convolutional Layer using deformable convolution operation\n",
        "class DeformableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, deformable_groups=1):\n",
        "        super(DeformableConv2d, self).__init__()\n",
        "\n",
        "        # Set convolutional layer parameters\n",
        "        self.kernel_size, self.stride, self.padding, self.dilation = (kernel_size, kernel_size), (stride, stride), padding, dilation\n",
        "\n",
        "        # Define the deformable convolutional layer components\n",
        "        self.modulator, self.offset_conv, self.final_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, deformable_groups, kernel_size=self.kernel_size, stride=stride, padding=self.padding, dilation=self.dilation, bias=False),\n",
        "            nn.Conv2d(in_channels, deformable_groups * 2, kernel_size=self.kernel_size, stride=stride, padding=self.padding, dilation=self.dilation, bias=False),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=self.kernel_size, stride=stride, padding=self.padding, dilation=self.dilation, bias=False)\n",
        "        )\n",
        "\n",
        "    def deformed_feature(self, x):\n",
        "        \"\"\"\n",
        "        Generate deformed feature maps using deformable convolution operation.\n",
        "\n",
        "        Parameters:\n",
        "        - x (torch.Tensor): Input feature map.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Deformed feature map.\n",
        "        \"\"\"\n",
        "        N, C, H, W = x.shape\n",
        "\n",
        "        # Create a grid for offset calculation\n",
        "        grid_y, grid_x = torch.meshgrid(torch.arange(H).to(device=x.device), torch.arange(W).to(device=x.device))\n",
        "\n",
        "        # Calculate offset using offset convolution\n",
        "        grid_y, grid_x = (grid_y.view(1, H, W) + self.offset_conv(x)[:, 0, :, :]), (grid_x.view(1, H, W) + self.offset_conv(x)[:, 1, :, :])\n",
        "\n",
        "        # Interpolate features using bilinear interpolation\n",
        "        grid = torch.stack((2 * grid_x / (W - 1) - 1, 2 * grid_y / (H - 1) - 1), dim=-1)\n",
        "        features = nn.functional.grid_sample(x, grid, mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Apply modulation to the deformed features\n",
        "        return features * 2 * torch.sigmoid(self.modulator(x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the deformable convolutional layer.\n",
        "\n",
        "        Parameters:\n",
        "        - x (torch.Tensor): Input feature map.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Output feature map.\n",
        "        \"\"\"\n",
        "        return self.final_conv(self.deformed_feature(x))\n",
        "\n",
        "# Instantiate a Deformable Convolutional Layer\n",
        "deformable_conv = DeformableConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, deformable_groups=1)\n",
        "\n",
        "# Generate random input data\n",
        "test = torch.randn(6, 32, 224, 224)  # (#samples, #in channels, #heights, #width)\n",
        "\n",
        "# Perform a forward pass through the Deformable Convolutional Layer\n",
        "out = deformable_conv(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "K7SeQ-UiAATl"
      },
      "outputs": [],
      "source": [
        "# Object Detector Neural Network Module\n",
        "class ObjectDetector(nn.Module):\n",
        "    def __init__(self, n_class, deformable=False):\n",
        "        \"\"\"\n",
        "        Constructor for the ObjectDetector class.\n",
        "\n",
        "        Parameters:\n",
        "        - n_class (int): Number of object classes.\n",
        "        - deformable (bool): Flag indicating whether to use deformable convolutional layers.\n",
        "        \"\"\"\n",
        "        super(ObjectDetector, self).__init__()  # Use super() to call the nn.Module constructor\n",
        "        conv = nn.Conv2d if not deformable else DeformableConv2d\n",
        "\n",
        "\n",
        "        # Define the blocks of the neural network architecture\n",
        "        self.e11, self.e12, self.pool1 = nn.Sequential(\n",
        "            conv(3, 64, kernel_size=3, padding=1),\n",
        "            conv(64, 64, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.e21, self.e22, self.pool2 = nn.Sequential(\n",
        "            conv(64, 128, kernel_size=3, padding=1),\n",
        "            conv(128, 128, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.e31, self.e32, self.pool3 = nn.Sequential(\n",
        "            conv(128, 256, kernel_size=3, padding=1),\n",
        "            conv(256, 256, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.e41, self.e42, self.pool4 = nn.Sequential(\n",
        "            conv(256, 512, kernel_size=3, padding=1),\n",
        "            conv(512, 512, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.e51, self.e52 = conv(512, 1024, kernel_size=3, padding=1), conv(1024, 1024, kernel_size=3, padding=1)\n",
        "\n",
        "        # Output layer components\n",
        "        self.outconv, self.fc_layers, self.BN, self.sigmoid = nn.Conv2d(1024, n_class, kernel_size=1), nn.Sequential(\n",
        "            nn.Linear(17640, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 256), nn.ReLU(),\n",
        "            nn.Linear(256, n_class)\n",
        "        ), nn.BatchNorm1d(n_class), nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the Object Detector network.\n",
        "\n",
        "        Parameters:\n",
        "        - x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Output tensor.\n",
        "        \"\"\"\n",
        "        # Forward pass through the network architecture\n",
        "        out = self.outconv(relu(self.e52(relu(self.e51(self.pool4(relu(self.e42(\n",
        "            relu(self.e41(self.pool3(relu(self.e32(relu(self.e31(\n",
        "                self.pool2(relu(self.e22(relu(self.e21(self.pool1(\n",
        "                    relu(self.e12(relu(self.e11(x)))))))))))))))))))))))))\n",
        "\n",
        "        # Apply batch normalization, sigmoid activation, and fully connected layers to the flattened output\n",
        "        return self.sigmoid(self.BN(self.fc_layers(out.view(out.shape[0], -1))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UhkychTV9sxM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "64b5197f-02a2-4a19-d964-246dae475567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "--------------------\n",
            "LR 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/160 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-eef7ae8b16d4>\u001b[0m in \u001b[0;36m<cell line: 134>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# Train the model using the defined parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mObjectDetector_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_metrics_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-eef7ae8b16d4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mall_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [16, 90] at entry 0 and [6, 90] at entry 1"
          ]
        }
      ],
      "source": [
        "def train_model(model, optimizer, scheduler, num_epochs=20):\n",
        "    \"\"\"\n",
        "    Train the given model using the specified optimizer and scheduler for a certain number of epochs.\n",
        "\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): The model to be trained.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer used for updating model parameters.\n",
        "        scheduler (torch.optim.lr_scheduler._LRScheduler): The learning rate scheduler.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: The trained model.\n",
        "        dict: Output metrics including precision, recall, F1 score, and loss for both training and validation sets.\n",
        "    \"\"\"\n",
        "    output_metrics = {'f1': {'train': [], 'val': []},\n",
        "                      'precision': {'train': [], 'val': []},\n",
        "                      'recall': {'train': [], 'val': []},\n",
        "                      'loss': {'train': [], 'val': []}\n",
        "                      }\n",
        "\n",
        "    all_metrics = ['precision', 'recall', 'f1', 'loss']\n",
        "\n",
        "    dataloaders = {\n",
        "        'train': train_data_loader1,\n",
        "        'val': test_data_loader}\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    epoch_loss = 0\n",
        "    losses = []\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 20)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    print(\"LR\", param_group['lr'])\n",
        "\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            all_predicted = []\n",
        "            all_targets = []\n",
        "            for index, (inputs, labels) in enumerate(tqdm(dataloaders[phase])):\n",
        "                inputs = inputs.to(device).float()\n",
        "                labels = labels.to(device).float()\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    metrics['loss'] += loss.data.cpu().numpy() * labels.size(0)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                all_predicted.extend(predicted.cpu().numpy().flatten())\n",
        "                all_targets.extend(labels.cpu().numpy().flatten())\n",
        "\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            temp = [0, 0, 0, 0]\n",
        "            temp[0], temp[1], temp[2], _ = precision_recall_fscore_support(all_targets, all_predicted,\n",
        "                                                                           average='binary')\n",
        "            temp[3] = metrics['loss'] / epoch_samples\n",
        "            for index, metric in enumerate(all_metrics):\n",
        "                output_metrics[metric][phase].append(temp[index])\n",
        "\n",
        "            outputs = []\n",
        "            for k in metrics.keys():\n",
        "                outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "            print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print(\"saving best model\")\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "        # save the checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }\n",
        "        torch.save(checkpoint, f'/content/drive/My Drive/DEEP/HW3/Q2/checkpoints/model_checkpoint{epoch}.pth')\n",
        "\n",
        "        # Save the dictionary to a file\n",
        "        with open('/content/drive/My Drive/DEEP/dictionary_conv_deform.pickle', 'wb') as file:\n",
        "            pickle.dump(output_metrics, file)\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, output_metrics\n",
        "\n",
        "\n",
        "# Instantiate the ObjectDetector model\n",
        "model = ObjectDetector(90).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "# Define the learning rate and alpha (smoothing constant)\n",
        "learning_rate = 1e-3\n",
        "alpha = 0.9  # You can adjust this value based on your needs\n",
        "\n",
        "# Define the RMSprop optimizer with alpha\n",
        "optimizer_ft = torch.optim.RMSprop(model.parameters(), lr=learning_rate, alpha=alpha)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "# Train the model using the defined parameters\n",
        "ObjectDetector_model, output_metrics_cov = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=50)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "25b05e4795a1531d3b55a0058bc302082de6595a5bd8f40643b8c42ae422adc8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}